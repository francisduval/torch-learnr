---
title: "Getting started with torch"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```

## What is torch?

**Torch** is an R package with 2 core features:

-   Array computation with strong GPU accelation

-   Deep neural networks built on a tape-based autograd system

### Why torch?

::: {.row}
::: {.col-md-6}
-   Torch is based on PyTorch, a framework which's rapidly increasing popularity among deep learning researchers.

-   We believe others can use torch's GPU acceleration to implement fast machine learning algorithms using it's convenient interface.

-   Torch is flexible and has a low level API making it useful for a vast range of use cases, not only for deep learning.

    </div>

    <div class="col-md-6">

![Papers with code [trends](https://paperswithcode.com/trends) section.](images/Screen%20Shot%202020-11-01%20at%2017.07.12.png){width="100%"}
:::
:::

## How it's implemented?

Before going into code it's nice to understand the basic of how torch is implemented in R.

::: {.row}
::: {.col-md-6}
-   Almost all `torch_*` functions are autogenerated from LibTorch's declaration file. This means that all low level operations are automatically available in the R package.

-   Most Neural network modules, optimizers and datasets and dataloaders code is writen in R. It's easy to inspect the code and use it to write your own customizations.

-   The diagram shows LibTorch in the bottom and all the layers implemented to allow using torch from R.

-   Differently from TensorFlow for R that is built on top of the Python implementation via reticulate, torch is built on top of LibTorch, the C++ API of PyTorch and thus, `torch` has no Python dependency.

    </div>

    <div class="col-md-6">

![Implementation diagram.](images/implementation.png){width="100%"}
:::
:::

## Torch components

The torch package has a few core components that we will discuss in this tutorial.

::: {.row}
::: {.col-md-6}
![Components of the torch package.](images/components.png){width="100%"}
:::
:::


Some of the components can be classified as low-level like:

-   **Tensors**: a multi-dimensional array container. Tensors are used to represent data and parameters in torch.

-   **Array computation library**: Torch includes more than 200 functions that can be used to transform tensors, including mathematical operations, structure transformations, etc.

-   **Autograd**: allows computing exact derivatives of tensor operations, this is essential to allow torch to be used for machine learning.

Torch also provides higher level abstractions that make it easier to build larger programs:

-   **Neural network modules**: `nn_modules` are a higher level abstraction to make it easy to handle state when composing many tensor operations.

-   **Datasets**: an abstraction for loading data in torch. It allows handling data that you might not be able to load entirely into a single tensor because of memory limitations.

-   **Dataloaders**: simplifies loading a dataset into batches and allows distributing data-loading into multiple processes.
